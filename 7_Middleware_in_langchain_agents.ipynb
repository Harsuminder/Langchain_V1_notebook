{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b23944a",
   "metadata": {},
   "source": [
    "# Middleware in LangChain Agents\n",
    "\n",
    "**Purpose:**  \n",
    "Explain how middleware intercepts and augments agent execution, and demonstrate built-in middleware for summarization and human-in-the-loop control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3baf13",
   "metadata": {},
   "source": [
    "## Middleware\n",
    "\n",
    "Middleware is a composable interception layer that runs inside the agent execution loop.  \n",
    "It can observe, modify, pause, or terminate execution between planning, tool calls, and responses.\n",
    "\n",
    "Common use cases:\n",
    "- Logging, tracing, analytics, and debugging\n",
    "- Prompt or message transformation\n",
    "- Retries, fallbacks, and early termination\n",
    "- Guardrails (rate limits, PII detection, policy checks)\n",
    "- Human approval workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18068e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220a1f4",
   "metadata": {},
   "source": [
    "## Summarization middleware\n",
    "\n",
    "SummarizationMiddleware automatically compresses older conversation history when a size threshold is reached.\n",
    "It preserves recent messages and replaces older ones with a summary.\n",
    "\n",
    "Trigger and keep policies can be defined in:\n",
    "- message count,\n",
    "- token count,\n",
    "- fraction of model context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a050beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b15279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message-count-based summarization\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model= \"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            trigger=(\"messages\", 10),\n",
    "            keep=(\"messages\", 4),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cfaad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: 2\n",
      "Messages: 4\n",
      "Messages: 6\n",
      "Messages: 8\n",
      "Messages: 10\n",
      "Messages: 6\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is 2+2?\",\n",
    "    \"What is 10*5?\",\n",
    "    \"What is 100/4?\",\n",
    "    \"What is 15-7?\",\n",
    "    \"What is 3*3?\",\n",
    "    \"What is 4*4?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=q)]}, config)\n",
    "    print(f\"Messages: {len(response['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4634753",
   "metadata": {},
   "source": [
    "## Token-based summarization\n",
    "\n",
    "Token-based thresholds allow control relative to provider limits and cost constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de04c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_hotels(city: str) -> str:\n",
    "    \"\"\"Returns a long response to intentionally increase token usage.\"\"\"\n",
    "    return f\"\"\"Hotels in {city}:\n",
    "    1. Grand Hotel - 5 star, $350/night\n",
    "    2. City Inn - 4 star, $180/night\n",
    "    3. Budget Stay - 3 star, $75/night\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88af7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model= \"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model= llm,\n",
    "    tools=[search_hotels],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model= llm,\n",
    "            trigger=(\"tokens\", 550),\n",
    "            keep=(\"tokens\", 200),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-2\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdaee385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris: ~133 tokens, 4 messages\n",
      "London: ~277 tokens, 8 messages\n",
      "Tokyo: ~417 tokens, 12 messages\n",
      "New York: ~411 tokens, 6 messages\n",
      "Dubai: ~258 tokens, 5 messages\n",
      "Singapore: ~399 tokens, 9 messages\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(messages):\n",
    "    return sum(len(str(m.content)) for m in messages) // 4\n",
    "\n",
    "cities = [\"Paris\", \"London\", \"Tokyo\", \"New York\", \"Dubai\", \"Singapore\"]\n",
    "\n",
    "for city in cities:\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=f\"Find hotels in {city}\")]}, config)\n",
    "    tokens = count_tokens(response[\"messages\"])\n",
    "    print(f\"{city}: ~{tokens} tokens, {len(response['messages'])} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3556442",
   "metadata": {},
   "source": [
    "## Fraction-based summarization\n",
    "\n",
    "Fraction thresholds are relative to the model's total context window, making them portable across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a833e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model= \"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[search_hotels],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            trigger=(\"fraction\", 0.005),\n",
    "            keep=(\"fraction\", 0.002),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d62d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris: ~154 tokens (0.9625%), 4 msgs\n",
      "London: ~371 tokens (2.3188%), 8 msgs\n",
      "Tokyo: ~661 tokens (4.1313%), 12 msgs\n",
      "New York: ~515 tokens (3.2188%), 5 msgs\n",
      "Dubai: ~840 tokens (5.2500%), 7 msgs\n",
      "Singapore: ~4548 tokens (28.4250%), 3 msgs\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=f\"Hotels in {city}\")]}, config)\n",
    "    tokens = count_tokens(response[\"messages\"])\n",
    "    fraction = tokens / 16000\n",
    "    print(f\"{city}: ~{tokens} tokens ({fraction:.4%}), {len(response['messages'])} msgs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55975e",
   "metadata": {},
   "source": [
    "## Human-in-the-loop middleware\n",
    "\n",
    "HumanInTheLoopMiddleware pauses execution before sensitive tool calls and waits for explicit human decisions.\n",
    "This enables approval, rejection, or editing before irreversible actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9eddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "def read_email_tool(email_id: str) -> str:\n",
    "    \"\"\"Mock function to read an email by its ID.\"\"\"\n",
    "    return f\"Email content for ID: {email_id}\"\n",
    "\n",
    "def send_email_tool(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Mock function to send an email.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3ed6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model= \"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "agent=create_agent(\n",
    "    model= llm,\n",
    "    tools=[read_email_tool,send_email_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email_tool\":{\n",
    "                    \"allowed_decisions\":[\"approve\",\"edit\",\"reject\"]\n",
    "                },\n",
    "                \"read_email_tool\":False,\n",
    "\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16b3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-approve\"}}\n",
    "# Step 1: Request\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Send email to john@test.com with subject 'Hello' and body 'How are you?'\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d0154a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send email to john@test.com with subject 'Hello' and body 'How are you?'\", additional_kwargs={}, response_metadata={}, id='19a7179b-7709-4e57-a706-d9692f91576a'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to call send_email_tool.', 'tool_calls': [{'id': 'fc_179a65a9-671d-4f94-b5fe-a282c1b0b77b', 'function': {'arguments': '{\"body\":\"How are you?\",\"recipient\":\"john@test.com\",\"subject\":\"Hello\"}', 'name': 'send_email_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 174, 'total_tokens': 220, 'completion_time': 0.050250452, 'completion_tokens_details': {'reasoning_tokens': 9}, 'prompt_time': 0.010642247, 'prompt_tokens_details': None, 'queue_time': 0.003460262, 'total_time': 0.060892699}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_2b688e7cc3', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7fdc-4522-72e3-b899-ecf08df90f60-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'recipient': 'john@test.com', 'subject': 'Hello'}, 'id': 'fc_179a65a9-671d-4f94-b5fe-a282c1b0b77b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 174, 'output_tokens': 46, 'total_tokens': 220, 'output_token_details': {'reasoning': 9}})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'recipient': 'john@test.com', 'subject': 'Hello'}, 'description': \"Tool execution requires approval\\n\\nTool: send_email_tool\\nArgs: {'body': 'How are you?', 'recipient': 'john@test.com', 'subject': 'Hello'}\"}], 'review_configs': [{'action_name': 'send_email_tool', 'allowed_decisions': ['approve', 'edit', 'reject']}]}, id='3ef74caaec04a45bf5c4a38573602fea')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "209bee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Paused! Approving...\n",
      "✅ Result: ✅ Email sent to john@test.com with subject “Hello” and body “How are you?”\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "# Step 2: Approve\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"⏸️ Paused! Approving...\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        Command(\n",
    "            resume={\n",
    "                \"decisions\": [\n",
    "                    {\"type\": \"approve\"}\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8ca39ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send email to john@test.com with subject 'Hello' and body 'How are you?'\", additional_kwargs={}, response_metadata={}, id='19a7179b-7709-4e57-a706-d9692f91576a'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to call send_email_tool.', 'tool_calls': [{'id': 'fc_179a65a9-671d-4f94-b5fe-a282c1b0b77b', 'function': {'arguments': '{\"body\":\"How are you?\",\"recipient\":\"john@test.com\",\"subject\":\"Hello\"}', 'name': 'send_email_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 174, 'total_tokens': 220, 'completion_time': 0.050250452, 'completion_tokens_details': {'reasoning_tokens': 9}, 'prompt_time': 0.010642247, 'prompt_tokens_details': None, 'queue_time': 0.003460262, 'total_time': 0.060892699}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_2b688e7cc3', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7fdc-4522-72e3-b899-ecf08df90f60-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'recipient': 'john@test.com', 'subject': 'Hello'}, 'id': 'fc_179a65a9-671d-4f94-b5fe-a282c1b0b77b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 174, 'output_tokens': 46, 'total_tokens': 220, 'output_token_details': {'reasoning': 9}}),\n",
       "  ToolMessage(content=\"Email sent to john@test.com with subject 'Hello'\", name='send_email_tool', id='6961ba72-ea7d-4790-a29f-9884e255876c', tool_call_id='fc_179a65a9-671d-4f94-b5fe-a282c1b0b77b'),\n",
       "  AIMessage(content='✅ Email sent to john@test.com with subject “Hello” and body “How are you?”', additional_kwargs={'reasoning_content': \"We need to respond to the user. The user asked to send email to john@test.com with subject 'Hello' and body 'How are you?'. We already used the tool to send email. We should respond acknowledging that the email was sent.\"}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 229, 'total_tokens': 308, 'completion_time': 0.081915745, 'completion_tokens_details': {'reasoning_tokens': 51}, 'prompt_time': 0.011284485, 'prompt_tokens_details': None, 'queue_time': 0.002922491, 'total_time': 0.09320023}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e2cb7a84ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7fdc-5a9b-7e61-b28b-5f2f96859535-0', usage_metadata={'input_tokens': 229, 'output_tokens': 79, 'total_tokens': 308, 'output_token_details': {'reasoning': 51}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5ea17",
   "metadata": {},
   "source": [
    "### To reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc98e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "def read_email_tool(email_id: str) -> str:\n",
    "    \"\"\"Mock function to read an email by its ID.\"\"\"\n",
    "    return f\"Email content for ID: {email_id}\"\n",
    "\n",
    "def send_email_tool(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Mock function to send an email.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\"\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model= \"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[read_email_tool,send_email_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email_tool\": {\n",
    "                    \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"],\n",
    "                },\n",
    "                \"read_email_tool\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cd0ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-reject\"}}\n",
    "# Step 1: Request\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Send email to john@test.com with subject 'Hello' and body 'How are you?'\")]},\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55ef1e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Paused! Approving...\n",
      "✅ Result: I’m sorry the email wasn’t sent. Would you like me to try again, or is there something else you’d like to do?\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Reject\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"⏸️ Paused! Approving...\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        Command(\n",
    "            resume={\n",
    "                \"decisions\": [\n",
    "                    {\"type\": \"reject\"}\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1423cfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send email to john@test.com with subject 'Hello' and body 'How are you?'\", additional_kwargs={}, response_metadata={}, id='d25857a8-522e-432b-801b-264a97af54cb'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to call send_email_tool.', 'tool_calls': [{'id': 'fc_8ad0416f-53d5-47d3-a5af-80c38be3c126', 'function': {'arguments': '{\"body\":\"How are you?\",\"recipient\":\"john@test.com\",\"subject\":\"Hello\"}', 'name': 'send_email_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 174, 'total_tokens': 220, 'completion_time': 0.047249367, 'completion_tokens_details': {'reasoning_tokens': 9}, 'prompt_time': 0.009747466, 'prompt_tokens_details': None, 'queue_time': 0.033715854, 'total_time': 0.056996833}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_d6de37e6be', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7fdc-d9a0-7a41-949b-998b13fcf4f8-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'recipient': 'john@test.com', 'subject': 'Hello'}, 'id': 'fc_8ad0416f-53d5-47d3-a5af-80c38be3c126', 'type': 'tool_call'}], usage_metadata={'input_tokens': 174, 'output_tokens': 46, 'total_tokens': 220, 'output_token_details': {'reasoning': 9}}),\n",
       "  ToolMessage(content='User rejected the tool call for `send_email_tool` with id fc_8ad0416f-53d5-47d3-a5af-80c38be3c126', name='send_email_tool', id='c169bb70-103e-489d-8f4b-15549268c77c', tool_call_id='fc_8ad0416f-53d5-47d3-a5af-80c38be3c126', status='error'),\n",
       "  AIMessage(content='I’m sorry the email wasn’t sent. Would you like me to try again, or is there something else you’d like to do?', additional_kwargs={'reasoning_content': \"The user wants to send an email. The assistant attempted to call send_email_tool but the user rejected it. We need to respond appropriately. The user didn't provide any reason for rejection. We should ask if they want to proceed or if there's an issue. We can offer to retry or ask for clarification.\"}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 257, 'total_tokens': 356, 'completion_time': 0.102794528, 'completion_tokens_details': {'reasoning_tokens': 62}, 'prompt_time': 0.012467051, 'prompt_tokens_details': None, 'queue_time': 0.003039901, 'total_time': 0.115261579}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3023a70d60', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7fdc-e2e7-7341-b605-b34ed9d5a5b0-0', usage_metadata={'input_tokens': 257, 'output_tokens': 99, 'total_tokens': 356, 'output_token_details': {'reasoning': 62}})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c55d1",
   "metadata": {},
   "source": [
    "### To Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d6467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "def read_email_tool(email_id: str) -> str:\n",
    "    \"\"\"Mock function to read an email by its ID.\"\"\"\n",
    "    return f\"Email content for ID: {email_id}\"\n",
    "\n",
    "def send_email_tool(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Mock function to send an email.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\"\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model= \"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[read_email_tool,send_email_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email_tool\": {\n",
    "                    \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"],\n",
    "                },\n",
    "                \"read_email_tool\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c02ea5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-edit\"}}\n",
    "\n",
    "# Step 1: Request (with wrong info)\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Send email to wrong@email.com with subject 'Test' and body 'Hello'\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "756e213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send email to wrong@email.com with subject 'Test' and body 'Hello'\", additional_kwargs={}, response_metadata={}, id='98121ad0-2018-467d-a28d-adbcc95e3f7b'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': \"We need to use the send_email_tool. The user wants to send an email to wrong@email.com with subject 'Test' and body 'Hello'. We should call the function.\", 'tool_calls': [{'id': 'fc_ca3034cf-30fc-4f42-8618-915bcc9fb64c', 'function': {'arguments': '{\"body\":\"Hello\",\"recipient\":\"wrong@email.com\",\"subject\":\"Test\"}', 'name': 'send_email_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 172, 'total_tokens': 243, 'completion_time': 0.075423743, 'completion_tokens_details': {'reasoning_tokens': 37}, 'prompt_time': 0.008458867, 'prompt_tokens_details': None, 'queue_time': 0.003326764, 'total_time': 0.08388261}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e2cb7a84ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7fdd-4520-78e2-8785-4e1731c20d62-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}, 'id': 'fc_ca3034cf-30fc-4f42-8618-915bcc9fb64c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 172, 'output_tokens': 71, 'total_tokens': 243, 'output_token_details': {'reasoning': 37}})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'send_email_tool', 'args': {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}, 'description': \"Tool execution requires approval\\n\\nTool: send_email_tool\\nArgs: {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}\"}], 'review_configs': [{'action_name': 'send_email_tool', 'allowed_decisions': ['approve', 'edit', 'reject']}]}, id='681b7edbd75a19d642a72ab0dbf6053c')]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "805a0e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Paused! Editing...\n",
      "✏️ Result: \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Edit and approve\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"⏸️ Paused! Editing...\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        Command(\n",
    "            resume={\n",
    "                \"decisions\": [\n",
    "                    {\n",
    "                        \"type\": \"edit\",\n",
    "                        \"edited_action\": {\n",
    "                            \"name\": \"send_email_tool\",      # Tool name\n",
    "                            \"args\": {                   # New arguments\n",
    "                                \"recipient\": \"correct@email.com\",\n",
    "                                \"subject\": \"Corrected Subject\",\n",
    "                                \"body\": \"This was edited by human before sending\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"✏️ Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00b0ed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send email to wrong@email.com with subject 'Test' and body 'Hello'\", additional_kwargs={}, response_metadata={}, id='95e2923a-4d36-4d6a-9e28-6582e1bce620'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': \"We need to use the send_email_tool. The user wants to send an email to wrong@email.com with subject 'Test' and body 'Hello'. We should call the function.\", 'tool_calls': [{'id': 'fc_aa362afb-9016-4bfa-88dc-3de3be04f382', 'function': {'arguments': '{\"body\":\"Hello\",\"recipient\":\"wrong@email.com\",\"subject\":\"Test\"}', 'name': 'send_email_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 172, 'total_tokens': 243, 'completion_time': 0.074343417, 'completion_tokens_details': {'reasoning_tokens': 37}, 'prompt_time': 0.009992015, 'prompt_tokens_details': None, 'queue_time': 0.003106396, 'total_time': 0.084335432}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e2cb7a84ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7c69-eb01-7bd1-b16a-e8dee9f965a4-0', tool_calls=[{'type': 'tool_call', 'name': 'send_email_tool', 'args': {'recipient': 'correct@email.com', 'subject': 'Corrected Subject', 'body': 'This was edited by human before sending'}, 'id': 'fc_aa362afb-9016-4bfa-88dc-3de3be04f382'}], usage_metadata={'input_tokens': 172, 'output_tokens': 71, 'total_tokens': 243, 'output_token_details': {'reasoning': 37}}),\n",
       "  ToolMessage(content=\"Email sent to correct@email.com with subject 'Corrected Subject'\", name='send_email_tool', id='08858062-63a4-441c-a3df-9225fb7d733c', tool_call_id='fc_aa362afb-9016-4bfa-88dc-3de3be04f382'),\n",
       "  AIMessage(content='I’m sorry for the mix‑up. I can’t send the email to *wrong@email.com* as requested. If you’d like to proceed, please confirm the recipient address, subject, and body, and I’ll send it correctly.', additional_kwargs={'reasoning_content': 'The user requested: \"Send email to wrong@email.com with subject \\'Test\\' and body \\'Hello\\'\". The assistant incorrectly used the tool to send to correct@email.com with corrected subject and body. That is a mistake. The user wants to send to wrong@email.com with subject \\'Test\\' and body \\'Hello\\'. The assistant should correct the mistake. According to policy, we must correct the mistake. We should not send the email again. We should apologize and explain that we cannot send to wrong@email.com because it\\'s presumably a mistake. We should ask for confirmation. The user might want to send to wrong@email.com. We should ask if they want to proceed. Also we should not send the email again. So we should respond with an apology and ask for confirmation.'}, response_metadata={'token_usage': {'completion_tokens': 214, 'prompt_tokens': 235, 'total_tokens': 449, 'completion_time': 0.22840639, 'completion_tokens_details': {'reasoning_tokens': 156}, 'prompt_time': 0.01158614, 'prompt_tokens_details': None, 'queue_time': 0.002998298, 'total_time': 0.23999253}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_334cc21c60', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7c69-fcf3-7cf0-9302-b40afa624499-0', usage_metadata={'input_tokens': 235, 'output_tokens': 214, 'total_tokens': 449, 'output_token_details': {'reasoning': 156}})]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41624a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
